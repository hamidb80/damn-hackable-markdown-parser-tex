# الف) بارگذاری و بررسی داده‌ها

## توضیح ویژگی ها
مجموعه داده دیابت (به نام Pima Indians Diabetes Dataset شناخته می‌شود) یک مجموعه داده معروف در یادگیری ماشین برای پیش‌بینی دیابت نوع ۲ برای **زنان** است. 

1. **ستون Pregnancies**: تعداد بارداری‌های قبلی  
2. **ستون Glucose**: غلظت گلوکز پلاسما در آزمایش تحمل گلوکز (دو ساعته)  
3. **ستون BloodPressure**: فشار خون سیستولیک (mm Hg)  
4. **ستون SkinThickness**: ضخامت چین پوستی سه‌سر بازویی 
5. **ستون Insulin**: میزان انسولین سرمی دو ساعته  
6. **ستون BMI**: شاخص توده بدنی
7. **ستون DiabetesPedigreeFunction**: تابعی که ارث‌گرایی دیابت را بر اساس سابقه خانوادگی نشان می‌دهد  
8. **ستون Age**: سن فرد (سال)  
9. **ستون Outcome**: دسته هدف – وجود دیابت


## چند نمونه از مجموعه داده
![[P4-LR-sample-5-dataset.png]]
// 5 نمونه داده از مجموعه داده دیابت

 ## بررسی توزیع ویژگی ها 
 ![[P4-LR-features-histogram.png]]
 // نمودار هیستوگرام ویژگی های مجموعه داده دیابت

- تعداد داده ها با توجه به ویژگی outcome به طور **غیر متوازن** هستند. 
- بیشتر ویژگی ها از توزیع گوسی پیروی نمیکنند، بخاطر همین استفاده از Logistic-Regression احتمالا نتیجه خوبی به همراه ندارد.
---
# ب) پیاده‌سازی Logistic-Regression با Gradient-Descent

## تئوری 
### تعریف

تابع Logistic-Regression به صورت زیر تعریف میشود:
$$
h(z) = \frac{1}{1+e^{-z}}
$$
که در آن مقدار $z$ از رابطه زیر محاسبه میشود:
$$
z = \beta + \omega_1 x_1 + \omega_2 x_2 + ... + \omega_n x_n
$$
که $\beta$ و $\omega_i$ پارامتر های قابل یادگیری هستند. $x_i$ ها نیز ویژگی های ما هستند. 

> نکته قابل توجه این است که ویژگی های دسته ای برای استفاده در این مدل، باید به صورت عددی تبدیل شوند، ویژگی های عددی نیز باید **نرمال سازی** شوند.


### تابع خطا یا loss
برای فهمیدن اینکه چه مقدار خطا داشتیم، از تابع log-loss استفاده میکنیم:
$$
\mathcal{L}_{\text{avg}} = -\frac{1}{N} \sum_{i=1}^{N} \left[ y_i \ln(h_i) + (1 - y_i) \ln(1 - h_i) \right]
$$
دلیل استفاده از این تابع نسبت به MSE این است که منحنی این تابع به صورت محدب (convex) است، چیزی که هنگام تمرین دادن با Gradient-Decent بسیار مهم است تا دچار بهینه نسبی نشویم و به بهینه کل برسیم.


### فرآیند یادگیری

یادگیری به این صورت است که در هر مرحله، با توجه به نوع Gradient-Decent، تعداد داده انتخاب کرده و میانگین خطای آن ها را با تابع ذکر شده محاسبه میکنیم. حالا از مشتق خطا برای بروزرسانی مقادیر جدید پارامتر ها استفاده میکنیم:
$$
\beta' \gets  \beta - \alpha \cdot \frac{\partial \mathcal{L}}{\partial \beta} \\
$$
$$
\omega_i' \gets  \omega_i - \alpha \cdot \frac{\partial \mathcal{L}}{\partial \omega_i}
$$

که در آن $\alpha$ **ضریب یادگیری** است. بنابر قاعده زنجیره ای مشتق داریم:
$$
\frac{\partial \mathcal{L}}{\partial \beta} = \frac{\partial \mathcal{L}}{\partial h}\times \frac{\partial h}{\partial z}\times \frac{\partial z}{\partial \beta} 
$$
$$
\frac{\partial \mathcal{L}}{\partial \omega_i} = \frac{\partial \mathcal{L}}{\partial h}\times \frac{\partial h}{\partial z}\times \frac{\partial z}{\partial \omega_i} 
$$
هر جزء را به صورت جدا مجاسبه میکنیم:
$$
 \frac{\partial \mathcal{L}}{\partial h} = -(\frac{y}{h} - \frac{1-y}{1-h})
$$

$$
 \frac{\partial h}{\partial z} = h(1-h)
$$

$$
 \frac{\partial z}{\partial \omega_i} = x_i
$$

$$
 \frac{\partial z}{\partial \beta} = 1
$$
 که با جایگذاری داریم:
$$
\frac{\partial \mathcal{L}}{\partial \omega_i} = -[y(1-h)-(1-y)h]\times x_i
$$
$$
\frac{\partial \mathcal{L}}{\partial \beta} = -[y(1-h)-(1-y)h]\times 1
$$
که در نهایت با قرار دادن مقادیر ممکن $y$ که $1$ و $0$ هستند، به عبارت زیر میرسیم:

$$
\frac{\partial \mathcal{L}}{\partial \omega_i} = (h-y) \times x_i
$$
$$
\frac{\partial \mathcal{L}}{\partial \beta} = (h-y)
$$
پس برای بروزرسانی پارامتر ها، تنها کافیست در هر مرحله اختلاف بین مقدار پیشبینی شده و مقدار واقعی را حساب کنیم.

## ذخیره کد ها
کلاس `LogisticRegression` به همراه کلاس های `GradientDescent` پیاده سازی شد. کد مربوطه در فایل `P4.ipynb` برای این بخش، و بخش های دیگر در فایل `utils/logistic_regression/impl.py` ذخیره شده است. 

# ج) آموزش و ارزیابی مدل
برای تمرین دادن مدل Logistic-Regression باید داده ها را نرمال سازی کرد و بدون این کار، نتیجه کاملا خراب میشود. 
![[P4-LR-accuracy-logloss-table.png| 200]]
// مقادیر accuracy و log-loss برای مدل Logistic-Regression از مجموعه داده دیابت

# د) رسم منحنی ROC و محاسبه AUC
![[P4-LR-ROC.png]]
مقدار AUC برابر $0.73$ بود.

---
# هـ) مقایسه مدل‌ها

## انتخاب معیار مناسب

### مشکلات معیار های رایح

- معیار accuracy دقیق نیست (دسته ها متوازن نیستند)
- معیار recall نیز FP ها را در نظر نمیگیرد
- معیار precision نیز FN ها را رها میکند.

### معیار f1-score
معیار جایگزین f1-score که ترکیبی از recall و precision است، مناسب تر است. اما در این معیار، معیار های recall و precision به یک اندازه اهمیت دارند، که با توجه به موضوع مجموعه داده ما که پزشکی و تشخیص بیماری است، اصلا به این صورت نیست

### معیار f2-score
این بحث ها همه به این معنی است که معیار های فعلی به تنهایی هیچ کدام کافی به نظر نمیرسد، برای این موارد یکی از راه حل ها، استفاده از معیار f2-score است، که در حقیقت همان f1-score است که میتوان به precision و recall ضریب نسبت داد، فرمول آن به صورت زیر است:
$$
F_{2} = (1 + \beta^{2}) \times \frac{\mathrm{precision} \times \mathrm{recall}}{(\beta^{2} \times \mathrm{precision}) + \mathrm{recall}}
$$

که در آن $\beta$ با توجه به نیاز این گونه تنظیم میشود:
* **مساوی 1**: معادل همان f1-score 
* **بزرگ تر از 1**: وقتی که recall مهم تر است
* **کوچک تر از 1**: وقتی precision مهم تر است

برای کاربرد پزشکی، مقدار $\beta=2$ را انتخاب میکنم و این به این معنی است که معیار recall برای من به اندازه 2 برابر معیار precision ارزش دارد. حالا جدول را با این معیار مرتب میکنیم:
![[P4-LR-best-models-high-FPR.png]]
// جدول میانگین مدل های منتخب به همراه معیار جدید f2-score با ارزیابی متقاطع از مجموعه داده دیابت

اما حالا شاهد مدل هایی هستیم که FPR به شدت بالایی دارند. برای استفاده پزشکی مقدار FPR باید حداکثر 20% باشد. پس برای تاثیر FPR معیار جدید f3-score را تعریف میکنم به طوری که:
$$
F_3 = F_2 \times (1-FPR)^\omega
$$
که در آن $\omega$ میزان اهمیت مقدار FPR است که فعلا آن را 1 در نظر میگیرم.
![[P4-LR-best-models-add-f3score.png]]
// جدول میانگین مدل های منتخب به همراه معیار جدید f3-score با ارزیابی متقاطع از مجموعه داده دیابت

---

## بدست آوردن بهترین حالت
### مدل KNN
![[P4-LR-best-results.png]]
// جدول میانگین بیشترین امتیاز برای معیار f3-score برای تنظیمات مختلف KNN از مجموعه داده دیابت

برای مدل KNN، بهترین تنظیم شامل فاصله Manhattan و تابع وزن دهی ثابت و مقدار K برابر با 15 است.

### مدل درخت تصمیم
![[P4-LR-best-results-DT.png]]
// جدول میانگین بیشترین امتیاز برای معیار f3-score برای تنظیمات مختلف درخت تصمیم از مجموعه داده دیابت

برای مدل درخت تصمیم، بهترین تنظیم شامل انتخاب تابع معیار Gini و حداکثر عمق 3 است.

### مدل Gaussian Naive Bayes
![[P4-LR-best-results-GNB.png]]
// جدول میانگین بیشترین امتیاز برای معیار f3-score برای تنظیمات مختلف GBN از مجموعه داده دیابت
بهترین Threshold (مرز) برای مدل GNB عدد $-0.4$ است.

### مدل Logistic regression 

// جدول میانگین بیشترین امتیاز برای معیار f3-score برای تنظیمات مختلف LR از مجموعه داده دیابت
![[P4-LR-best-results-LR.png]]
بهترین Threshold (مرز) برای مدل Logistic Regression عدد $0.4$ است.
---
## جمع بندی و تحلیل
![[P4-LR-best-models-results.png]]
// // جدول میانگین مدل های منتخب با ارزیابی متقاطع از مجموعه داده دیابت

مدل GNB بهترین عملکرد را داشت، احتمالا بخاطر اینکه _فرض مستقل شرطی بودن_ برای داده های مورد استفاده تا حد خوبی برقرار بود. اما نتیجه برای هیچکدام از مدل ها برای کاربرد پزشکی که نیازمند recall بیش از $0.8$ هستند، کافی نیست.
---
# و) اعتبارسنجی متقاطع در مقایسه نهایی

## میانگین و انحراف معیار 
![[P4-LR-best-models-results-again.png]]
// جدول میانگین مدل های منتخب با ارزیابی متقاطع از مجموعه داده دیابت
![[P4-LR-best-models-results-stdev.png]]
// جدول انحراف معیار مدل های منتخب با ارزیابی متقاطع از مجموعه داده دیابت

از جداول میانگین و انجراف معیار مشخص است که مدل GBN بهترین میانگین و کمترین اختلاف معیار را داشته است، پس انتخاب آن به عنوان بهترین مدل در قسمت قبل پیشبینی درستی بوده است.


---
## انتخاب بهترین
![[P4-LR-best-models-pointplot.png]]
// نمودار نقطه ای میانگین و انحراف معیار f3-score مدل های برتر بر اثر ارزیابی متاقاطع برای مجموعه داده دیابت

با توجه به معیار انتخاب شده، مدل GNB بهترین عملکرد را داشت.

---
## نمودار ROC و مقادیر AUC
![[P4-LR-best-models-ROC.png]]
// نمودار ROC مدل های منتخب از مجموعه داده دیابت
![[P4-LR-best-models-AUC.png| 300]]
// مقادیر AUC متناظر نمودار های ROC مدل های منتخب از مجموعه داده دیابت

به نظر بنده نمودار ROC  و مقدار AUC هیچ چیز خاصی را بیان نمیکند، چون
- بسته به کاربرد معیار ها و استدلال ها میتواند متفاوت باشد. 
- برای برخی مدل ها مدل درخت تصمیم یا KNN این معیار پیوسته نیست و AUC آن ها قابل مقایسه با مدل هایی مثل GBN که ROC پیوسته دارند، معنی خاصی ندارد.
بخاطر همین صرف تحلیل از روی مقادیر در جدول اطلاعات خیلی بیشتری به متخصص برای تصمیم گیری میدهد.

---
# ز) پیاده‌سازی روش‌های مختلف Gradient-Descent

قبل تر مدل Logistic-Regression با روش batch روی Gradient-Decent پیاده سازی شد.

روش batch یا همان full-batch مقدار loss را روی همه داده های train محاسبه میکند که این حالتی ایده آل است و برای مجموعه داده های بسیار بزرگ واقعا این کار مشکل و سرعت به شدت پایینی دارد.

روش ُstochastic برخلاف روش batch، تنها یک داده را به صورت تصادفی از مجموعه داده های تمرینی انتخاب میکند و loss را فقط برای همان داده محاسبه و بر اساس آن پارامتر ها را تنظیم میکند. 

روش دیگر mini-batch که بین این دو روش batch و stochastic است، مقدار معینی از داده را به صورت تصادفی در نظر میگیرد. میتوان روش batch را یک mini-batch با اندازه تمام داده های تمرینی و stochastic را یک mini-batch با اندازه 1 در نظر گرفت.

![[P4-LR-GDC-variants-comparison.png]]
// نودار loss بر حسب epoch برای بهینه ساز mini-batch با اندازه های مختلف برای مدل Logistic-Regression و مجموعه داده دیابت

براساس توضیحات بالا، انتظار میرود که نمودار loss برحسب epoch برای حالت batch به صورت نرم و نسبتا کاهشی باشد و هرچه اندازه batch را کم کنیم، رفتار ها هیجانی تر و غیرقابل پیشبینی تر شود؛ به طوری که در حالت stochastic تقریبا برخلاف بقیه همگرایی وجود ندارد.

برای داشتن یک تناسب خوبی از همگرایی و سرعت، معمولا از mini-batch استفاده میکنند که اندازه آن بر اساس کاربرد و نتایج میتواند کمی متفاوت باشد.